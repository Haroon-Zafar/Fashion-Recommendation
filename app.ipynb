{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.layers import GlobalMaxPooling2D\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the ResnEt50 model and loading the weights, top layer is false because we will add own ours\n",
    "# Standard Image size 224, 224, 3\n",
    "\n",
    "model = ResNet50(weights='imagenet', include_top=False,\n",
    "                 input_shape=(224, 224, 3))\n",
    "\n",
    "# our model is already trained on imagenet, so we will freeze the layers\n",
    "# using model to predict the image\n",
    "# only adding the top layers\n",
    "\n",
    "model.trainable = False\n",
    "\n",
    "# passing our model , and adding the top layers\n",
    "\n",
    "\n",
    "# for debugging\n",
    "# print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractFeatures(img_path):\n",
    "\n",
    "    # we have to preprocess the image before passing it to the model\n",
    "    # we will use the preprocess_input function from keras\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "\n",
    "    # converting the image to array\n",
    "    imgArray = image.img_to_array(img)\n",
    "\n",
    "    # converting imgArray dimensions 224,224,3 to 1,224,224,3\n",
    "    # why ? because keras work on batches of images not single image\n",
    "    # if you have 100 images then you will have 100,224,224,3\n",
    "    # if you have single image you have to tell keras that it is a batch of 1 image\n",
    "    # resizing images\n",
    "    # will give 4D array\n",
    "    expandedImgArray = np.expand_dims(imgArray, axis=0)\n",
    "\n",
    "    # preprocessing the image\n",
    "    # preprocess_input is a function that will format the image into the format that the model expects\n",
    "    preProcessedImg = preprocess_input(expandedImgArray)\n",
    "\n",
    "    # predict() function enables us to predict the labels of the data values on the basis of the trained model.\n",
    "    result = model.predict(preProcessedImg, verbose=0).flatten()\n",
    "\n",
    "    # normalized result\n",
    "    normalizedResult = result / norm(result)\n",
    "\n",
    "    return (normalizedResult)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 27/44441 [00:08<2:22:28,  5.20it/s]"
     ]
    }
   ],
   "source": [
    "# Now we are making a list in which we place the file names of the images in the folder `image`\n",
    "# I want to print the names of the images in the folder `image` in the terminal\n",
    "\n",
    "fileNames = []\n",
    "\n",
    "# print(os.listdir('images'))\n",
    "\n",
    "# for loop will traverse through every file in the folder `images`\n",
    "# we are appending file names to the list `fileNames`\n",
    "\n",
    "for file in os.listdir('images'):\n",
    "    fileNames.append(os.path.join('images', file))\n",
    "\n",
    "# print(len(fileNames))\n",
    "# print(fileNames[0:5])\n",
    "\n",
    "\n",
    "# we just have to call this extractFeatures function for every image in the folder `images`\n",
    "# it will return a list of features for every image in the folder `images`\n",
    "\n",
    "# we will store the features in a list\n",
    "featuresList = []\n",
    "\n",
    "# tqdm is a progress bar library in python, here it tells progress of for loop\n",
    "\n",
    "for file in tqdm(fileNames):\n",
    "    featuresList.append(extractFeatures(file))\n",
    "\n",
    "\n",
    "print(np.array(featuresList).shape)\n",
    "\n",
    "\n",
    "# Dumping the featuresList into a file\n",
    "# wb = write binary\n",
    "\n",
    "pickle.dump(featuresList, open('featuresList.pkl', 'wb'))\n",
    "\n",
    "\n",
    "# Dumping the filenames into a file\n",
    "\n",
    "pickle.dump(fileNames, open('featuresList.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "69713e280fccb9aa802931bf1b98f79efcfe938b3ab1e86cc85b2e647522a81d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
